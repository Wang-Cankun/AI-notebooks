{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa75dbd",
   "metadata": {},
   "source": [
    "# Simple autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e984db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5592111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wan268/.conda/envs/dl/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "prediction = model(data)  # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc679e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0068e-01, -5.2057e-01, -4.2017e-01, -1.2647e+00, -5.0478e-01,\n",
       "          1.8201e-01, -1.3801e-01,  4.2159e-01,  3.6176e-01, -7.7721e-01,\n",
       "         -7.3244e-01, -3.5386e-01, -1.1883e-01, -7.1301e-01, -7.9938e-01,\n",
       "         -6.0982e-01, -8.4926e-01, -3.2990e-01, -4.1159e-01, -5.8680e-01,\n",
       "         -1.3093e+00, -3.9951e-01, -1.1348e+00,  5.1822e-01, -9.2160e-01,\n",
       "         -9.6355e-01, -5.3444e-01, -1.3327e+00, -7.7128e-01, -1.4207e-01,\n",
       "         -4.5393e-01, -7.7444e-01, -1.5041e-01, -5.1622e-01, -3.0619e-01,\n",
       "         -3.4039e-01,  5.2779e-01, -5.7775e-01, -3.0846e-01,  3.2483e-01,\n",
       "         -6.1573e-01, -6.5536e-01, -8.5377e-01, -1.5661e-01, -5.3701e-01,\n",
       "         -3.5975e-01, -7.0454e-01, -4.5725e-01, -1.2100e+00, -8.8316e-01,\n",
       "         -4.4823e-01,  4.7922e-01, -2.4586e-01, -4.6406e-01, -2.8528e-01,\n",
       "         -1.0659e+00, -5.5954e-01, -1.3556e+00, -3.4588e-01, -3.4513e-01,\n",
       "          8.8586e-01,  5.3778e-02,  1.6636e-01,  2.8274e-02, -7.0387e-01,\n",
       "         -1.5831e-01, -1.3709e-01, -1.7449e-01, -6.8087e-01, -1.0157e+00,\n",
       "         -1.5569e+00, -2.0729e-01, -1.2368e+00, -1.9510e-01, -1.2281e+00,\n",
       "         -1.1202e+00, -8.3868e-02, -6.3420e-01,  2.3957e-01,  1.1515e-01,\n",
       "         -4.3695e-01, -1.4580e+00,  2.1766e-01, -5.0146e-01, -5.0911e-01,\n",
       "          7.9076e-02,  4.8044e-01,  1.9675e-01, -1.1848e-01, -5.4458e-01,\n",
       "         -1.2311e+00, -8.8354e-01, -1.5403e+00, -4.5528e-01,  2.0967e-01,\n",
       "         -1.9219e+00, -7.5515e-01, -1.8205e-01, -1.2081e+00, -1.9825e-01,\n",
       "         -1.0803e+00, -6.7954e-01, -8.4512e-01, -1.9126e-01, -1.4856e-01,\n",
       "         -4.5935e-01, -4.4604e-01, -1.2961e+00, -7.2044e-01, -1.3826e+00,\n",
       "         -9.3369e-01, -6.0753e-01,  1.2318e+00,  6.5353e-01,  3.5992e-01,\n",
       "         -9.0286e-01, -6.6589e-01, -2.3467e-01,  7.7532e-01, -1.4596e-01,\n",
       "         -5.7597e-01, -7.8388e-03,  3.5472e-01,  2.7818e-02,  9.9490e-01,\n",
       "         -2.5687e-01,  4.9063e-01, -1.2685e+00, -9.4180e-01, -8.6555e-01,\n",
       "         -1.3189e+00, -1.4550e+00, -9.7718e-01, -1.2348e+00, -4.7605e-01,\n",
       "         -1.3181e+00, -7.6164e-01, -9.0481e-01, -1.0651e+00, -1.4418e+00,\n",
       "         -1.3647e+00, -1.5544e+00, -1.9728e+00, -1.1524e+00, -4.3882e-01,\n",
       "         -1.7712e-01, -7.9530e-01, -1.6411e+00, -9.1093e-01, -1.2299e+00,\n",
       "          3.6302e-01,  1.4102e+00, -9.7408e-01, -5.5757e-01, -2.7231e-02,\n",
       "          1.9682e-01, -2.7210e-01, -1.6187e-01,  1.3061e-01,  2.2363e-01,\n",
       "          4.4116e-01,  5.9596e-01,  2.0210e-01,  5.3898e-01,  4.1321e-01,\n",
       "          2.8128e-02, -9.1185e-02, -3.1587e-01,  6.0562e-01, -2.5910e-01,\n",
       "         -1.0552e-01,  7.5863e-01,  2.9816e-01,  1.5331e-01,  3.4047e-02,\n",
       "         -6.4997e-01, -3.7379e-02, -1.5956e-01,  5.8186e-01,  9.3640e-01,\n",
       "          7.7090e-01, -2.2912e-01,  2.9978e-01,  1.3670e-02,  2.4214e-01,\n",
       "          7.4734e-01,  4.0569e-01,  1.3194e-02,  1.9257e-01,  4.9441e-01,\n",
       "         -5.3540e-01,  3.1237e-01,  3.8029e-01,  4.5330e-01, -6.0710e-01,\n",
       "          5.1095e-01, -1.1262e-01,  2.1320e-01, -7.4358e-02,  5.7255e-01,\n",
       "          2.3225e-01,  2.1865e-01,  4.9856e-01,  4.9824e-01,  7.1065e-02,\n",
       "          2.8010e-01, -6.3787e-02,  7.7633e-01,  1.4095e+00,  5.1874e-01,\n",
       "         -5.4213e-02,  3.7864e-01,  3.6762e-01, -6.0901e-02,  7.3778e-02,\n",
       "          3.4111e-01,  7.4510e-03,  3.5598e-01, -4.0653e-01,  6.4301e-01,\n",
       "          2.6746e-01, -1.0028e-01,  1.2870e-02,  4.4751e-01,  3.3577e-01,\n",
       "          4.6569e-01,  2.3920e-01,  1.0309e+00, -4.3621e-01, -4.9117e-02,\n",
       "          1.1407e-01,  6.4732e-01,  4.7596e-01, -5.0697e-02,  1.1093e+00,\n",
       "          8.9821e-01,  6.8798e-01,  2.0347e-01,  9.3737e-01,  1.8362e-01,\n",
       "          8.8154e-01,  1.6454e-01,  5.9890e-01,  4.9247e-01, -1.0833e-01,\n",
       "          3.8903e-01,  5.3511e-01,  1.5688e-01,  5.6939e-01,  3.7534e-01,\n",
       "          3.9873e-01,  5.0311e-01, -9.3954e-01,  8.1024e-01,  6.1553e-01,\n",
       "         -4.9463e-01,  6.9233e-01,  4.3247e-01, -1.8137e-01,  3.5202e-01,\n",
       "         -7.7536e-02, -6.7612e-01, -4.0037e-01,  4.1981e-01,  6.5583e-01,\n",
       "          5.1732e-01,  1.2154e-01,  5.3873e-01, -1.9855e-01, -6.0490e-01,\n",
       "         -1.0058e+00, -1.0907e+00, -6.0637e-01,  5.7963e-01, -1.4042e+00,\n",
       "         -1.1057e+00, -1.2381e+00, -9.6872e-01, -1.3951e+00, -8.8888e-01,\n",
       "         -4.6056e-01,  7.8916e-01,  5.3431e-01,  1.0111e-01,  1.1745e-01,\n",
       "          7.8797e-01, -4.3865e-01, -3.1191e-01, -7.2431e-01, -1.8463e+00,\n",
       "         -1.1438e+00, -1.2521e+00, -3.8518e-01, -9.0211e-01, -8.4379e-01,\n",
       "         -9.2046e-01, -1.1675e+00, -1.3361e+00, -3.6242e-01, -2.5124e-01,\n",
       "         -1.7038e+00, -7.4576e-01, -4.6210e-01, -5.4894e-01, -1.3359e+00,\n",
       "         -8.3379e-01,  1.9440e-01, -1.1284e+00, -1.3831e+00, -6.7772e-01,\n",
       "          8.0985e-02, -4.0186e-01, -4.1429e-01,  3.2463e-02,  5.5430e-01,\n",
       "         -5.3197e-01, -1.2896e+00, -1.2241e+00, -1.3676e+00, -6.7918e-01,\n",
       "         -1.5961e+00, -9.1339e-01, -1.2863e+00, -1.5310e+00, -1.5382e+00,\n",
       "         -1.6174e+00, -1.3451e+00,  3.0924e-01,  1.0252e-02, -4.9194e-01,\n",
       "          7.7572e-02, -3.0432e-01, -7.6527e-02,  1.1785e-02, -4.9287e-01,\n",
       "         -6.7970e-01, -1.5455e+00,  2.9556e-01,  7.3148e-01, -1.1961e+00,\n",
       "         -5.4490e-01,  5.7176e-01, -5.6775e-01, -1.5860e+00, -6.7731e-01,\n",
       "          6.8016e-01, -4.6178e-01, -1.5114e+00, -3.6173e-01, -1.5085e+00,\n",
       "         -1.2665e+00, -1.9557e+00, -1.2571e+00, -6.2823e-01, -7.2992e-01,\n",
       "          2.3997e-01,  1.0275e+00,  9.4218e-02,  6.1943e-01,  4.5292e-01,\n",
       "         -2.4955e-01,  5.8655e-01, -3.1132e-02,  3.5159e-01, -4.0239e-01,\n",
       "         -5.3636e-01, -1.1671e+00, -4.0901e-01, -8.2203e-01, -6.7295e-01,\n",
       "         -6.8106e-01, -3.1998e-01, -5.8427e-01,  1.5780e-01, -4.4528e-01,\n",
       "         -1.2470e+00, -1.1236e+00,  2.2230e-01, -3.8863e-01, -6.5978e-01,\n",
       "          2.7265e-01, -3.0181e-01, -1.2363e-01, -5.0418e-01, -5.9624e-01,\n",
       "         -2.2692e-01, -8.2365e-01, -1.2151e+00, -1.2013e+00, -3.6036e-03,\n",
       "          8.7541e-01,  3.5756e-01, -1.2813e+00, -1.5204e+00,  9.3846e-02,\n",
       "          7.7162e-01, -1.1543e+00, -7.5523e-01,  5.7088e-01,  1.5783e-01,\n",
       "         -1.2638e+00,  4.3124e-01, -5.2950e-02, -1.9440e+00, -1.6887e+00,\n",
       "         -6.1975e-01, -1.5957e-01, -4.5660e-01,  6.0285e-02,  8.6585e-01,\n",
       "         -2.1162e-01,  2.6789e-01,  2.2032e+00,  6.4200e-01,  1.4941e-01,\n",
       "          9.9888e-01,  3.6873e-02,  1.7151e-01, -6.4868e-03,  9.3772e-01,\n",
       "          6.9650e-01,  1.2379e+00, -4.2147e-01,  4.0260e-01,  1.9941e-01,\n",
       "         -9.1817e-01, -1.3681e-02,  1.2435e+00,  1.7318e+00,  7.5751e-01,\n",
       "         -8.4175e-01, -1.3854e-01,  1.3748e-01,  4.9439e-01,  4.0576e-01,\n",
       "          7.7894e-01, -3.8295e-01, -5.9895e-02,  3.1550e-01,  2.1627e-01,\n",
       "          1.1478e+00,  5.8256e-01,  2.9500e-01, -1.0389e+00, -3.6703e-01,\n",
       "          3.1631e-01,  2.9876e-01,  1.5835e+00,  8.8960e-01, -6.2093e-01,\n",
       "         -1.7293e-01,  4.4141e-01,  4.5933e-01, -8.0579e-02, -3.0009e-01,\n",
       "          4.0459e-01,  1.5870e+00,  7.7760e-01, -8.5112e-02,  7.8109e-01,\n",
       "         -5.4631e-01,  4.7198e-01,  1.4626e+00,  2.4553e+00,  8.4387e-01,\n",
       "         -3.0034e-01, -1.2555e+00, -7.3888e-02, -1.3201e-01,  1.7096e+00,\n",
       "          1.0298e+00,  4.9453e-01,  7.3034e-02,  7.0433e-01, -2.1786e-01,\n",
       "         -2.2468e-01,  7.8279e-02,  4.6423e-01,  7.3327e-01,  2.5421e-01,\n",
       "          9.1527e-02, -4.5133e-03,  3.1883e-01, -7.7174e-01, -1.2051e+00,\n",
       "         -1.9047e-01, -7.0281e-01,  6.6654e-01,  1.5861e+00,  1.1210e+00,\n",
       "          4.2338e-01,  8.9578e-01,  6.4781e-01, -1.1405e+00,  1.1026e+00,\n",
       "         -9.7843e-01, -4.6331e-02, -5.0593e-01, -2.1835e-01,  1.2418e+00,\n",
       "         -1.9923e+00,  4.9935e-01,  1.1265e+00,  6.1885e-01,  8.6065e-01,\n",
       "          9.8831e-01,  1.1377e+00,  2.0121e-01,  4.0787e-01,  3.5429e-01,\n",
       "         -1.0460e+00, -7.1356e-01,  7.0435e-01,  1.9674e-01,  1.1422e+00,\n",
       "          1.6508e+00,  3.0570e-01, -1.1364e-02,  1.3193e+00,  7.2930e-01,\n",
       "         -9.9912e-01,  4.0371e-01,  1.1432e+00,  1.6296e+00,  2.1394e-01,\n",
       "         -6.3777e-01, -1.2019e-01, -3.2378e-01,  1.7868e-01,  1.9446e-02,\n",
       "          7.0847e-01,  6.1904e-02, -4.7886e-02, -9.2611e-01,  7.8526e-01,\n",
       "         -7.3010e-01, -3.8064e-01, -7.7353e-01, -1.3836e-01,  1.3506e+00,\n",
       "         -1.0317e+00,  1.3156e+00,  9.7931e-01,  5.3717e-01,  8.3952e-01,\n",
       "          6.3239e-01,  4.7431e-01, -1.9627e+00, -1.0280e+00, -7.1901e-02,\n",
       "         -6.4766e-01, -1.4128e-01,  6.9366e-01,  9.5739e-02, -1.3813e+00,\n",
       "         -6.2319e-01,  3.0311e-01,  6.0206e-01,  8.6833e-01,  9.9748e-01,\n",
       "         -1.2115e-01, -2.8596e-01,  9.8757e-01, -2.7945e-01, -1.0873e+00,\n",
       "         -7.4895e-01,  7.3540e-02,  1.4417e+00,  6.6532e-01, -5.4100e-01,\n",
       "          1.0300e+00,  1.6864e-01,  8.3486e-01, -8.4427e-01,  6.2827e-01,\n",
       "          7.7420e-02, -1.1604e+00,  1.0379e+00,  4.7307e-01,  1.5359e-01,\n",
       "          1.5725e-01, -1.9250e-01,  8.6508e-01,  8.6287e-01,  6.5026e-01,\n",
       "          5.9091e-01, -4.0989e-01,  1.8123e+00,  1.1264e+00,  8.5964e-01,\n",
       "         -4.1787e-01,  3.2675e-01, -6.2824e-01,  6.1944e-01, -3.3182e-02,\n",
       "         -4.1257e-01,  1.1514e+00, -2.5870e-01, -5.0072e-01,  8.6887e-01,\n",
       "          2.1844e+00,  1.7528e-02,  4.9844e-02, -6.8909e-01,  6.1916e-01,\n",
       "         -5.3494e-02,  1.3390e+00, -6.6184e-01,  4.6175e-01, -4.9158e-02,\n",
       "          5.9899e-01,  6.0947e-01, -5.5449e-01,  5.7292e-01,  4.7678e-02,\n",
       "          5.1582e-01,  1.1344e+00,  2.5191e-01,  1.8466e+00,  8.7605e-01,\n",
       "          1.1539e+00,  9.0270e-01, -1.9841e-01,  2.4768e-01,  2.7938e-01,\n",
       "         -1.4679e+00,  7.0583e-01, -4.6839e-01, -9.4436e-01, -1.2042e-01,\n",
       "         -4.3007e-02,  8.6470e-01,  6.3734e-01,  9.9267e-01, -6.8493e-02,\n",
       "         -1.0545e-02,  1.1978e+00,  7.6865e-01,  7.8127e-01,  2.7298e-01,\n",
       "         -1.7919e+00,  9.1828e-01,  4.0068e-02,  1.0906e+00,  1.0109e+00,\n",
       "         -8.4681e-01,  8.1082e-01,  3.2640e-01, -4.1664e-01, -1.3708e+00,\n",
       "          8.1043e-01,  2.3989e-01,  6.5268e-01,  9.3818e-01, -2.9347e-01,\n",
       "          7.5695e-01, -1.1012e-01,  2.6194e-01, -3.6693e-02,  4.7581e-01,\n",
       "         -1.2431e-01, -9.6268e-01, -1.1534e-02, -7.9373e-01,  1.1901e+00,\n",
       "         -6.6546e-02,  1.2701e+00,  1.4087e-01, -8.5635e-01, -6.7777e-01,\n",
       "          3.9732e-01, -1.4633e-01, -3.5528e-01,  4.8788e-01,  1.4678e+00,\n",
       "         -7.0148e-01,  1.6187e+00,  1.0872e+00,  7.5820e-01, -1.3797e-01,\n",
       "          4.8415e-01,  7.6563e-01, -5.6422e-01,  3.9459e-01,  3.6755e-01,\n",
       "         -1.7525e+00, -9.6864e-02, -1.1928e+00, -3.5085e-01, -7.8579e-01,\n",
       "         -6.0183e-01,  6.3388e-01,  9.0839e-01,  6.0626e-01, -1.0257e+00,\n",
       "          8.3086e-01,  1.4023e+00, -7.6121e-02, -3.4647e-01,  4.7421e-01,\n",
       "          1.9601e+00, -2.7795e-01,  1.9046e-02,  5.0039e-01,  6.4099e-01,\n",
       "         -4.7613e-01, -4.3536e-01,  4.1888e-01,  1.0516e+00, -2.7252e-01,\n",
       "          4.0780e-01,  8.9005e-01, -1.9978e-01, -3.2164e-01,  1.5482e-01,\n",
       "         -6.1611e-01,  6.4896e-01, -6.9241e-01, -8.4041e-02,  5.3495e-01,\n",
       "          1.0763e-01, -6.1446e-02,  1.2839e+00,  1.9887e-01, -5.6796e-01,\n",
       "          1.0039e+00, -4.6294e-01, -2.7735e-01,  1.4973e+00, -4.1037e-01,\n",
       "          3.2669e-01,  2.1994e+00, -8.7036e-01,  2.3809e+00, -1.7320e+00,\n",
       "          3.1144e-01, -1.2452e-01,  7.1707e-01,  9.5740e-01,  3.3451e-01,\n",
       "          8.1896e-01,  4.1543e-02,  4.9077e-01,  1.4580e-01,  9.1334e-01,\n",
       "          7.1048e-03, -2.5106e-01,  4.9372e-01,  4.7436e-01,  1.6503e+00,\n",
       "          3.3279e-01,  1.0368e-03,  3.0953e-01,  5.2218e-01,  8.9862e-01,\n",
       "         -7.1897e-01,  8.2737e-01, -3.4171e-01,  1.4363e+00, -2.7957e-01,\n",
       "          1.2479e-01,  6.4616e-01,  4.8110e-01,  5.0992e-01,  1.0805e+00,\n",
       "          1.0153e+00,  5.1700e-01,  1.7862e-01, -3.2047e-01,  1.0966e+00,\n",
       "          1.9788e-01,  5.5343e-01,  1.1390e+00,  2.7074e-01,  8.9568e-01,\n",
       "          5.5889e-01,  3.3329e-01,  3.9372e-01,  1.2332e+00, -8.1524e-01,\n",
       "         -6.9756e-01, -2.8339e-01,  1.1489e+00,  8.6862e-01,  1.4001e+00,\n",
       "         -9.1333e-02,  3.0050e-01,  1.3515e+00,  2.7299e-01,  8.3297e-02,\n",
       "          8.4535e-01,  1.1122e+00,  1.8071e+00,  7.4228e-01, -7.1372e-02,\n",
       "          1.9344e-01,  8.8748e-01,  5.7329e-01, -1.0554e+00,  3.2740e-01,\n",
       "         -7.7084e-01,  8.6637e-02, -8.8568e-01, -1.1829e+00,  7.1347e-01,\n",
       "          1.1250e+00,  4.1516e-01,  4.3302e-01,  1.0086e+00, -1.0165e-01,\n",
       "         -3.7434e-01,  1.0963e+00, -2.5159e-01,  1.6580e+00, -1.0011e+00,\n",
       "         -1.3513e-01, -2.9063e-02, -1.0885e+00,  1.7347e+00,  2.5944e-01,\n",
       "         -1.4699e+00, -8.9894e-01,  2.9237e-01,  3.2906e-01,  8.5991e-01,\n",
       "         -5.9952e-01,  1.2882e-01,  9.8893e-01,  1.2977e+00, -4.0447e-01,\n",
       "          8.7691e-01,  2.9022e-01, -7.0931e-01, -9.4703e-01,  2.4709e-01,\n",
       "          8.0331e-01,  1.4976e+00,  1.4624e+00,  1.1997e+00, -4.5748e-01,\n",
       "          1.4398e+00,  3.5242e-01,  3.6841e-01,  6.8296e-01,  5.3334e-01,\n",
       "          1.5916e+00,  8.6080e-01, -3.3383e-01,  2.3447e-01,  8.7994e-01,\n",
       "          1.0763e+00,  1.5372e+00,  1.9312e+00, -1.6894e-01, -6.5055e-01,\n",
       "          6.3217e-01, -4.0100e-01, -2.6899e-01, -1.6621e-01,  1.1112e+00,\n",
       "          4.0304e-01,  1.1522e+00,  7.0452e-01, -2.0837e-01, -5.6057e-01,\n",
       "          4.7946e-01,  6.6273e-02, -2.4396e-01,  1.4176e+00, -4.0246e-01,\n",
       "          8.9736e-01, -1.2883e+00,  9.7931e-01, -1.3519e+00, -2.3898e+00,\n",
       "          9.3961e-02,  1.3390e+00, -1.9344e-01, -3.5567e-01,  1.4908e+00,\n",
       "          1.1718e+00, -7.7471e-02,  1.1962e+00,  1.1941e+00, -1.8684e-01,\n",
       "          4.1863e-01, -2.7020e-01, -4.2484e-01, -9.2471e-01, -3.3280e-01,\n",
       "         -3.0197e-01,  1.9311e-01,  4.6243e-01,  1.1305e-01, -7.7695e-01,\n",
       "         -5.6817e-01,  8.7094e-01,  6.7299e-01,  1.7745e+00,  1.8521e+00,\n",
       "         -1.1274e+00, -4.8777e-01,  1.0139e+00,  8.9419e-01,  8.9634e-01,\n",
       "          2.1419e-01, -7.1174e-01,  1.4369e+00, -8.7546e-01,  1.1296e+00,\n",
       "          1.2880e+00,  9.7722e-01,  8.8249e-01, -5.5181e-01, -1.7836e+00,\n",
       "         -6.0938e-01,  3.4128e-01,  2.9003e-01,  3.1691e-01,  3.9978e-01,\n",
       "          3.6846e-02,  1.1302e+00, -6.6542e-01,  3.5985e-01, -4.3333e-01,\n",
       "         -9.8297e-01, -8.7809e-01, -5.3846e-01, -1.5124e-01,  1.4128e+00,\n",
       "          5.2739e-02, -1.0459e-01,  3.9335e-01, -1.8147e+00, -1.7141e-02,\n",
       "         -5.6076e-01,  7.1479e-01,  3.7953e-01, -1.4714e-01,  2.2275e-01,\n",
       "         -6.0089e-03, -2.9323e-01, -1.8798e-01,  4.3100e-01, -1.7862e-01,\n",
       "         -6.6843e-01, -8.3125e-01,  7.1858e-01,  6.5646e-01, -2.8054e-01,\n",
       "         -1.0579e-01, -3.6429e-01, -2.0429e-01,  1.7434e-01,  6.0416e-01,\n",
       "         -1.1573e-01, -2.3713e-01, -8.5927e-01,  3.7268e-02, -1.0254e+00,\n",
       "          4.3525e-01,  4.3963e-01, -2.6805e-01, -9.5918e-01, -1.0377e+00,\n",
       "         -2.2331e-01,  5.4736e-01, -5.3569e-01,  8.2802e-01,  2.2402e-01,\n",
       "         -3.8628e-02,  9.0813e-01, -1.3614e-01, -1.8923e-01, -1.7319e+00,\n",
       "          1.2475e+00, -1.4162e+00,  6.6808e-01,  5.0988e-01, -5.8051e-01,\n",
       "         -4.8118e-01,  1.7086e-02,  3.5433e-01, -6.6233e-01, -9.3098e-01,\n",
       "         -1.1683e+00, -2.3512e+00,  1.6359e+00, -9.8970e-02, -9.9718e-01,\n",
       "         -2.2861e-01, -1.1883e+00, -8.1366e-01, -1.8435e+00, -8.7487e-01,\n",
       "         -3.6763e-01,  3.7262e-01, -4.5596e-01,  1.5885e+00,  5.2670e-01]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a197fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward()  # backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa6bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc77a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08869f6e",
   "metadata": {},
   "source": [
    "# Details \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e46a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "b = torch.tensor([6.0, 4.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5bb712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q = 3 * a ** 3 - b ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad204ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  65.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb8ca48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1.0, 1.0])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b725289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "# check if collected gradients are correct\n",
    "print(9 * a ** 2 == a.grad)\n",
    "print(-2 * b == b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f1ba4",
   "metadata": {},
   "source": [
    "# Exclusion from the DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5866645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does `a` require gradients? : False\n",
      "Does `b` require gradients?: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 5)\n",
    "y = torch.rand(5, 5)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "print(f\"Does `a` require gradients? : {a.requires_grad}\")\n",
    "b = x + z\n",
    "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a55ea094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6674b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "987bedb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f44981af",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8982020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.01\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4134b2e",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a0e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55d11fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1.]), tensor([0., 0., 0.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e39199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x7f30ec1289d0>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward object at 0x7f30ec128790>\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient function for z =\", z.grad_fn)\n",
    "print(\"Gradient function for loss =\", loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce02d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ee9ddaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0402, 0.1622, 0.3149],\n",
       "        [0.0402, 0.1622, 0.3149],\n",
       "        [0.0402, 0.1622, 0.3149],\n",
       "        [0.0402, 0.1622, 0.3149],\n",
       "        [0.0402, 0.1622, 0.3149]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43f52225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0402, 0.1622, 0.3149])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5421a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
